{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c80bb34e-31f2-4f28-b52b-10588cd9bf8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/your/tiktok_transcripts.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(youtube_transcript_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     86\u001b[0m     youtube_transcript \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtiktok_transcripts_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     89\u001b[0m     tiktok_transcripts \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Find TikTok segments\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/your/tiktok_transcripts.txt'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "def write_file(file_path, content):\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "\n",
    "def check_match(segment, clip, min_words=8, fuzz_ratio=90):\n",
    "    for sentence in clip:\n",
    "        if len(word_tokenize(sentence)) >= min_words:\n",
    "            for seg_sentence in segment:\n",
    "                if fuzz.ratio(sentence, seg_sentence) >= fuzz_ratio:\n",
    "                    return True, [sentence]\n",
    "    return False, []\n",
    "\n",
    "def find_tiktok_segments(youtube_transcript, tiktok_transcripts, threshold=0.65):\n",
    "    tiktok_positions = []\n",
    "    youtube_sentences = sent_tokenize(youtube_transcript)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    for tiktok in tiktok_transcripts:\n",
    "        tiktok_sentences = sent_tokenize(tiktok)\n",
    "        \n",
    "        for i in range(len(youtube_sentences) - len(tiktok_sentences) + 1):\n",
    "            segment = youtube_sentences[i:i + len(tiktok_sentences)]\n",
    "            segment_str = ' '.join(segment)\n",
    "            \n",
    "            tfidf_matrix = vectorizer.fit_transform([segment_str, tiktok])\n",
    "            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "            \n",
    "            if similarity >= threshold:\n",
    "                start_pos = sum(len(s) for s in youtube_sentences[:i]) + i\n",
    "                end_pos = start_pos + len(tiktok)\n",
    "                tiktok_positions.append((start_pos, end_pos))\n",
    "                print(f\"Found TikTok segment at positions {start_pos, end_pos}\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Did not find TikTok segment: {tiktok[:30]}... in YouTube transcript.\")\n",
    "            \n",
    "    return tiktok_positions\n",
    "\n",
    "def segment_and_label_transcript(youtube_transcript, tiktok_positions):\n",
    "    tiktok_positions.sort()\n",
    "    segments = []\n",
    "    labels = []\n",
    "    last_end = 0\n",
    "    \n",
    "    for start, end in tiktok_positions:\n",
    "        if start > last_end:\n",
    "            segments.append(youtube_transcript[last_end:start])\n",
    "            labels.append(\"Non Tiktok - 0\")\n",
    "        \n",
    "        segments.append(youtube_transcript[start:end])\n",
    "        labels.append(\"Tiktok - 1\")\n",
    "        \n",
    "        last_end = end\n",
    "    \n",
    "    if last_end < len(youtube_transcript):\n",
    "        segments.append(youtube_transcript[last_end:])\n",
    "        labels.append(\"Non Tiktok - 0\")\n",
    "    \n",
    "    labeled_segments = [f\"{label}:\\n{segment}\\n\" for label, segment in zip(labels, segments)]\n",
    "    \n",
    "    return labeled_segments\n",
    "\n",
    "# File paths\n",
    "youtube_transcript_path = \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#51/#51 Would you lie for fame_55716-10-08_Powered by notta.ai.txt\"\n",
    "tiktok_paths = [\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#51/yt_51_1_55725-06-17_Powered by notta.ai.txt\",\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#51/yt_51_2_55725-06-17_Powered by notta.ai.txt\",\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#51/yt_51_3_55725-06-17_Powered by notta.ai.txt\",\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#51/yt_51_4_55725-06-17_Powered by notta.ai.txt\"\n",
    "]\n",
    "# Read files\n",
    "with open(youtube_transcript_path, 'r') as f:\n",
    "    youtube_transcript = f.read()\n",
    "\n",
    "with open(tiktok_transcripts_path, 'r') as f:\n",
    "    tiktok_transcripts = f.readlines()\n",
    "\n",
    "# Find TikTok segments\n",
    "tiktok_positions = find_tiktok_segments(youtube_transcript, tiktok_transcripts)\n",
    "\n",
    "# Segment and label the YouTube transcript\n",
    "labeled_segments = segment_and_label_transcript(youtube_transcript, tiktok_positions)\n",
    "\n",
    "# Write to file\n",
    "output_path = os.path.splitext(youtube_transcript_path)[0] + \"_labeled.txt\"\n",
    "with open(output_path, 'w') as f:\n",
    "    f.write(\"\\n\".join(labeled_segments))\n",
    "\n",
    "print(f\"Labeled segments have been written to {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Read files\n",
    "youtube_transcript = read_file(youtube_transcript_path)\n",
    "tiktok_transcripts = [read_file(path) for path in tiktok_paths]\n",
    "\n",
    "# Find, segment, and label\n",
    "tiktok_positions = find_tiktok_segments(youtube_transcript, tiktok_transcripts)\n",
    "segments = custom_segment_transcript(youtube_transcript, tiktok_positions)\n",
    "labeled_segments = label_segments(segments, tiktok_positions)\n",
    "\n",
    "# Write to file\n",
    "output_path = os.path.splitext(youtube_transcript_path)[0] + \"_labeled.txt\"\n",
    "labeled_content = label_segments(segments, tiktok_positions)\n",
    "write_file(output_path, labeled_content)\n",
    "\n",
    "print(f\"Labeled segments have been written to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28bddc-f837-4b19-8402-b1fddcbda6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4fdf9-cd70-462f-9376-dae5af31d09f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f05df-0138-4133-a6af-130c921d48a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
