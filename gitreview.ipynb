{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abadff8a-9a23-4808-950a-422f40d23ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching sentences: [\"That's what we kind of put death to the back of our Minds.\"]\n",
      "Matching sentences: [\"No,  You didn't say it like that.\"]\n",
      "Matching sentences: ['Is  She always making your sandwich with not enough ketchup in it?']\n",
      "Matching sentences: [\"Yeah, I'd love a sandwich.\"]\n",
      "Matching sentences: ['You you want a barbecue sauce on it?']\n",
      "Matching sentences: [\"No, I wouldn't put anything past them.\"]\n",
      "Matching sentences: [\"I'd be like, what the hell's going on?\"]\n",
      "Matching sentences: [\"You know, what the fuck's going on.\"]\n",
      "Matching sentences: [\"Are  You telling me I'm lying?\"]\n",
      "Matching sentences: [\"He's like, yeah, sorry.\"]\n",
      "Matching sentences: ['But all I can think is why are you putting that on TikTok?']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from fuzzywuzzy import fuzz\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to read transcript from a file\n",
    "def read_transcript(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "# Function to check for matching sentences or consecutive words using fuzzy matching\n",
    "def check_match(segment, clip, min_words=8, fuzz_ratio=90):\n",
    "    for sentence in clip:\n",
    "        if len(word_tokenize(sentence)) >= min_words:\n",
    "            for seg_sentence in segment:\n",
    "                if fuzz.ratio(sentence, seg_sentence) >= fuzz_ratio:\n",
    "                    return True, [sentence]\n",
    "    return False, []\n",
    "\n",
    "# Function to calculate segment_length based on tokens\n",
    "def calculate_segment_length(sentences):\n",
    "    token_count = 0\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        token_count += len(word_tokenize(sentence))\n",
    "        if 300 <= token_count <= 500:\n",
    "            return i + 1\n",
    "    return len(sentences)\n",
    "\n",
    "# Function to label segments with dynamic length and overlap\n",
    "# ... (previous imports and functions remain the same)\n",
    "\n",
    "# Function to label segments with dynamic length and overlap\n",
    "def label_segments(youtube_file, tiktok_files, overlap=5):\n",
    "    # Read YouTube transcript\n",
    "    youtube_transcript = read_transcript(youtube_file)\n",
    "    youtube_sentences = sent_tokenize(youtube_transcript)\n",
    "    \n",
    "    # Read TikTok transcripts\n",
    "    tiktok_clips = []\n",
    "    for file in tiktok_files:\n",
    "        tiktok_transcript = read_transcript(file)\n",
    "        tiktok_sentences = sent_tokenize(tiktok_transcript)\n",
    "        tiktok_clips.append(tiktok_sentences)\n",
    "    \n",
    "    # Segment YouTube transcript\n",
    "    segment_length = math.ceil(len(youtube_sentences) / 60)  # Adjust as needed\n",
    "    segments = [youtube_sentences[i:i + segment_length] for i in range(0, len(youtube_sentences), segment_length)]\n",
    "    \n",
    "    # Label segments\n",
    "    labels = []\n",
    "    used_sentences = set()  # Keep track of TikTok sentences that have already been used for labeling\n",
    "    for segment in segments:\n",
    "        label = 0\n",
    "        matching_sentences = []\n",
    "        for clip in tiktok_clips:\n",
    "            match, match_sentences = check_match(segment, clip)\n",
    "            if match:\n",
    "                # Check if the matching sentence has already been used for labeling\n",
    "                if not any(sentence in used_sentences for sentence in match_sentences):\n",
    "                    label = 1\n",
    "                    matching_sentences.extend(match_sentences)\n",
    "                    used_sentences.update(match_sentences)\n",
    "                    break\n",
    "        labels.append(label)\n",
    "        \n",
    "        # Print the matching sentences if label is 1\n",
    "        if label == 1:\n",
    "            print(f\"Matching sentences: {matching_sentences}\")\n",
    "        # Output labeled segments\n",
    "    labeled_segments = list(zip(segments, labels))\n",
    "    \n",
    "    # Write the labeled segments to a file\n",
    "    output_file_path = \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#24/24labeled_segments.txt\"\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for i, (segment, label) in enumerate(labeled_segments):\n",
    "            f.write(f\"Segment {i+1} (Label: {label}):\\n{' '.join(segment)}\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# File paths\n",
    "youtube_file = \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#24/#24 Trust ï½œ Cheating Partners, Death, Knife crime and being let down.txt\"\n",
    "tiktok_files = [\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#24/yt_24_1.txt\",\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#24/yt_24_2.txt\",\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#24/yt_24_3.txt\",\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#24/yt_24_4.txt\",\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#24/yt_24_5.txt\"\n",
    "]\n",
    "\n",
    "# Label the segments\n",
    "labeled_segments = label_segments(youtube_file, tiktok_files)\n",
    "\n",
    "# Print out some labeled segments for verification\n",
    "#for i, (segment, label) in enumerate(labeled_segments):\n",
    "    #print(f\"Segment {i+1} (Label: {label}):\\n{' '.join(segment)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690209c6-26c2-4477-a55e-5e44c6505e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dea5d2-ee74-4d7a-9b92-149d091d0928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
