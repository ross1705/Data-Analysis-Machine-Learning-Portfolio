{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c80bb34e-31f2-4f28-b52b-10588cd9bf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found TikTok segment at positions (5213, 7055)\n",
      "Found TikTok segment at positions (42474, 43393)\n",
      "Found TikTok segment at positions (72289, 73270)\n",
      "Did not find TikTok segment: \n",
      "Holly will it be and Phillips... in YouTube transcript.\n",
      "Labeled segments have been written to /Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#37/#37 The Mission _ Suicide letter, Angry Jamaican man and a Dagger up the A_se-CD6TlG1s4yk_55716-10-18_Powered by notta.ai_labeled.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "def write_file(file_path, content):\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "\n",
    "def check_match(segment, clip, min_words=8, fuzz_ratio=90):\n",
    "    for sentence in clip:\n",
    "        if len(word_tokenize(sentence)) >= min_words:\n",
    "            for seg_sentence in segment:\n",
    "                if fuzz.ratio(sentence, seg_sentence) >= fuzz_ratio:\n",
    "                    return True, [sentence]\n",
    "    return False, []\n",
    "\n",
    "def find_tiktok_segments(youtube_transcript, tiktok_transcripts, threshold=90):\n",
    "    tiktok_positions = []\n",
    "    youtube_sentences = sent_tokenize(youtube_transcript)\n",
    "    \n",
    "    for tiktok in tiktok_transcripts:\n",
    "        tiktok_sentences = sent_tokenize(tiktok)\n",
    "        max_similarity = 0\n",
    "        best_match = (0, 0)\n",
    "        \n",
    "        for i in range(len(youtube_sentences) - len(tiktok_sentences) + 1):\n",
    "            segment = youtube_sentences[i:i + len(tiktok_sentences)]\n",
    "            is_match, _ = check_match(segment, tiktok_sentences, fuzz_ratio=threshold)\n",
    "            \n",
    "            if is_match:\n",
    "                start_pos = sum(len(s) for s in youtube_sentences[:i]) + i  # +i for spaces between sentences\n",
    "                end_pos = start_pos + len(tiktok)\n",
    "                tiktok_positions.append((start_pos, end_pos))\n",
    "                print(f\"Found TikTok segment at positions {start_pos, end_pos}\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Did not find TikTok segment: {tiktok[:30]}... in YouTube transcript.\")\n",
    "            \n",
    "    return tiktok_positions\n",
    "\n",
    "\n",
    "def custom_segment_transcript(youtube_transcript, tiktok_positions):\n",
    "    segments = []\n",
    "    last_end = 0\n",
    "    for start, end in tiktok_positions:\n",
    "        if start > last_end:\n",
    "            segments.append(youtube_transcript[last_end:start])\n",
    "        segments.append(youtube_transcript[start:end])\n",
    "        last_end = end\n",
    "    if last_end < len(youtube_transcript):\n",
    "        segments.append(youtube_transcript[last_end:])\n",
    "    return segments\n",
    "\n",
    "def label_segments(segments, tiktok_positions):\n",
    "    labels = []\n",
    "    current_pos = 0\n",
    "    labeled_segments = []\n",
    "    for segment in segments:\n",
    "        segment_start = current_pos\n",
    "        segment_end = current_pos + len(segment)\n",
    "        label = \"Not TikTok-worthy\"\n",
    "        for start, end in tiktok_positions:\n",
    "            if segment_start == start and segment_end == end:\n",
    "                label = \"TikTok-worthy\"\n",
    "                break\n",
    "        labeled_segments.append(f\"{label}:\\n{segment}\\n\")\n",
    "        current_pos += len(segment)\n",
    "    return \"\".join(labeled_segments)\n",
    "\n",
    "# File paths\n",
    "youtube_transcript_path = \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#37/#37 The Mission _ Suicide letter, Angry Jamaican man and a Dagger up the A_se-CD6TlG1s4yk_55716-10-18_Powered by notta.ai.txt\"\n",
    "tiktok_paths = [\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#37/yt_37_1_55725-06-13_Powered by notta.ai.txt\",\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#37/yt_37_2_55725-06-13_Powered by notta.ai.txt\",\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#37/yt_37_3_55725-06-13_Powered by notta.ai.txt\",\n",
    "    \"/Users/rossjackson/Documents/VideoAnalysisProject/New_Project_Directory/TikTok:YT_Audios/#37/yt_37_4_55725-06-13_Powered by notta.ai.txt\"\n",
    "]\n",
    "\n",
    "# Read files\n",
    "youtube_transcript = read_file(youtube_transcript_path)\n",
    "tiktok_transcripts = [read_file(path) for path in tiktok_paths]\n",
    "\n",
    "# Find, segment, and label\n",
    "tiktok_positions = find_tiktok_segments(youtube_transcript, tiktok_transcripts)\n",
    "segments = custom_segment_transcript(youtube_transcript, tiktok_positions)\n",
    "labeled_segments = label_segments(segments, tiktok_positions)\n",
    "\n",
    "# Write to file\n",
    "output_path = os.path.splitext(youtube_transcript_path)[0] + \"_labeled.txt\"\n",
    "labeled_content = label_segments(segments, tiktok_positions)\n",
    "write_file(output_path, labeled_content)\n",
    "\n",
    "print(f\"Labeled segments have been written to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee000e28-a0d0-4360-bbe8-8be0b53fd140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
